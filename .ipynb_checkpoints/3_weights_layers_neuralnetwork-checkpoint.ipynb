{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "##### Build a neural network with 4 layers (3 weight layers) using Python Programming where Mean Squared Error and sigmoid activation function should be employed as its loss function and activation function, respectively. Also, momentum term should be included in this basic Neural Network structure and Batch Gradient Descent should be used for training. The MNIST data set is available at http://yann.lecun.com/exdb/mnist/***\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# linear algebra\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas as pd\n",
    "\n",
    "# scipy.special for sigmoid function\n",
    "import scipy.special\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Data import\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import time\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Layer class\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # Input X is computed into the output Y for every layers\n",
    "    def forwardProp(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    def backwardProp(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backwardPropmom(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and its derivative\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2));\n",
    "\n",
    "def mse_loss_derivative(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit from base class Layer\n",
    "class Dense(Layer):\n",
    "    # input_size = number of input neurons\n",
    "    # output_size = number of output neurons\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        self.weights = np.random.rand(inputSize, outputSize) - 0.5\n",
    "        self.bias = np.random.rand(1, outputSize) - 0.5\n",
    "        self.gamma=0.9\n",
    "        self.v=0\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forwardProp(self, inputData):\n",
    "        self.input = inputData\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    # computes dE/dW, dE/dB for a given outputError=dE/dY. Returns inputError=dE/dX.\n",
    "    def backwardProp(self, outputError, learningRate):\n",
    "        inputError = np.dot(outputError, self.weights.T)\n",
    "        weightsError = np.dot(self.input.T, outputError)\n",
    "        # dBias = outputError\n",
    "\n",
    "        # update parameters\n",
    "        self.weights -= learningRate * weightsError\n",
    "        self.bias -= learningRate * outputError\n",
    "        return inputError\n",
    "    \n",
    "    def backwardPropmom(self, outputError, learningRate):\n",
    "        inputError = np.dot(outputError, self.weights.T)\n",
    "        weightsError = np.dot(self.input.T, outputError)\n",
    "        # dBias = outputError\n",
    "\n",
    "        # update parameters\n",
    "        self.v = self.gamma*self.v -learningRate * weightsError\n",
    "        self.weights += self.v\n",
    "        self.bias -= learningRate * outputError\n",
    "        return inputError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit from base class Layer\n",
    "class ActivateLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forwardProp(self, inputData):\n",
    "        self.input = inputData\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    # Returns inputError=dE/dX for a given outputError=dE/dY.\n",
    "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
    "    def backwardProp(self, outputError, learningRate):\n",
    "        return self.activation_prime(self.input) * outputError\n",
    "    def backwardPropmom(self, outputError, learningRate):\n",
    "        return self.activation_prime(self.input) * outputError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.mse_loss= None\n",
    "        self.mse_loss_derivative = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use_lossfunc(self, mse_loss, mse_loss_derivative):\n",
    "        self.mse_loss = mse_loss\n",
    "        self.mse_loss_derivative = mse_loss_derivative\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict_output(self, inputData):\n",
    "        # sample dimension first\n",
    "        samples = len(inputData)\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = inputData[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forwardProp(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def accuracy(self,x_train,y_train,x_test,y_test):\n",
    "        train_accuracy=[]\n",
    "        test_accuracy=[]\n",
    "        size=len(x_train)\n",
    "        train_output=self.predict_output(x_train[0:size])\n",
    "        test_output=self.predict_output(x_test[0:size])\n",
    "        for i in range(1,size):\n",
    "            delta_train=mse_loss(y_train[0:i],train_output)\n",
    "            delta_test=mse_loss(y_train[0:i],test_output)\n",
    "            train_accuracy.append(delta_train)\n",
    "            test_accuracy.append(delta_test)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(train_accuracy, '-r', label=' Training accuracy')\n",
    "        ax.plot(test_accuracy, '-g', label=' Testing accuracy')\n",
    "        leg = ax.legend(title='Learning curves');\n",
    "\n",
    "        plt.show()\n",
    "        return train_accuracy,test_accuracy\n",
    "\n",
    "    # train the network\n",
    "    def train_network(self, x_train, y_train, epochs, learningRate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "        errorList = []\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forwardProp(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.mse_loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.mse_loss_derivative(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backwardProp(error, learningRate)\n",
    "                    \n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            errorList.append(err)\n",
    "            \n",
    "        # show error's graph\n",
    "        return errorList\n",
    "    \n",
    "    def train_network_mom(self, x_train, y_train, epochs, learningRate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "        errorList = []\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forwardProp(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.mse_loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.mse_loss_derivative(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backwardPropmom(error, learningRate)\n",
    "                    \n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            errorList.append(err)\n",
    "            \n",
    "        # show error's graph\n",
    "        return errorList\n",
    "    \n",
    "    def plot_learning_curves(self, X_train, X_test, y_train, y_test, size, iterations, learning_rate):\n",
    "        train_errors, test_errors = [], []\n",
    "\n",
    "        self.train_network(X_train[:size], y_train[:size], epochs=iterations, learningRate=learning_rate)\n",
    "\n",
    "        labels_train_predict = self.predict_output(X_train[:size])\n",
    "        labels_test_predict = self.predict_output(X_test[:size])\n",
    "\n",
    "        for m in range(1, size):\n",
    "            train_errors.append(mse_loss(y_train[:m], labels_train_predict))\n",
    "            test_errors.append(mse_loss(y_test[:m], labels_test_predict))\n",
    "\n",
    "        #plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "        #plt.plot(np.sqrt(test_errors), \"b-\", linewidth=3, label=\"test\")\n",
    "        #plt.legend(loc=\"upper right\", fontsize=14)\n",
    "        #plt.xlabel(\"Training set size\", fontsize=14)\n",
    "        #plt.plot(train_errors,label='train errors')\n",
    "        #plt.plot(test_errors,label='test errors')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork_mom:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.mse_loss= None\n",
    "        self.mse_loss_derivative = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use_lossfunc(self, mse_loss, mse_loss_derivative):\n",
    "        self.mse_loss = mse_loss\n",
    "        self.mse_loss_derivative = mse_loss_derivative\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict_output(self, inputData):\n",
    "        # sample dimension first\n",
    "        samples = len(inputData)\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = inputData[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forwardProp(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def accuracy(self,x_train,y_train,x_test,y_test):\n",
    "        train_accuracy=[]\n",
    "        test_accuracy=[]\n",
    "        size=len(x_train)\n",
    "        train_output=self.predict_output(x_train[0:size])\n",
    "        test_output=self.predict_output(x_test[0:size])\n",
    "        for i in range(1,size):\n",
    "            delta_train=mse_loss(y_train[0:i],train_output)\n",
    "            delta_test=mse_loss(y_train[0:i],test_output)\n",
    "            train_accuracy.append(delta_train)\n",
    "            test_accuracy.append(delta_test)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(train_accuracy, '-r', label=' Training accuracy')\n",
    "        ax.plot(test_accuracy, '-g', label=' Testing accuracy')\n",
    "        leg = ax.legend(title='Learning curves');\n",
    "\n",
    "        plt.show()\n",
    "        return train_accuracy,test_accuracy\n",
    "\n",
    "    \n",
    "    def train_network_mom(self, x_train, y_train, epochs, learningRate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "        errorList = []\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forwardProp(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.mse_loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.mse_loss_derivative(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backwardPropmom(error, learningRate)\n",
    "                    \n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            errorList.append(err)\n",
    "            \n",
    "        # show error's graph\n",
    "        return errorList\n",
    "    \n",
    "    def plot_learning_curves(self, X_train, X_test, y_train, y_test, size, iterations, learning_rate):\n",
    "        train_errors, test_errors = [], []\n",
    "\n",
    "        self.train_network(X_train[:size], y_train[:size], epochs=iterations, learningRate=learning_rate)\n",
    "\n",
    "        labels_train_predict = self.predict_output(X_train[:size])\n",
    "        labels_test_predict = self.predict_output(X_test[:size])\n",
    "\n",
    "        for m in range(1, size):\n",
    "            train_errors.append(mse_loss(y_train[:m], labels_train_predict))\n",
    "            test_errors.append(mse_loss(y_test[:m], labels_test_predict))\n",
    "\n",
    "        #plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "        #plt.plot(np.sqrt(test_errors), \"b-\", linewidth=3, label=\"test\")\n",
    "        #plt.legend(loc=\"upper right\", fontsize=14)\n",
    "        #plt.xlabel(\"Training set size\", fontsize=14)\n",
    "        #plt.plot(train_errors,label='train errors')\n",
    "        #plt.plot(test_errors,label='test errors')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "plt.figure(figsize=[6,6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.title(\"Label: %i\"%y_train[i])\n",
    "    plt.imshow(X_train[i].reshape([28,28]),cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data : 60000 samples\n",
    "# reshape and normalize input data\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28*28)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "# transform the output (number from 0 to 9) into a vector\n",
    "# for example: number 2 will become [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "# same for test data : 10000 samples\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28*28)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Activation : Sigmoid Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigmoid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b9bc1d3e6a1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# prepare the plot, associate the color r(ed) or b(lue) and the label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmoidFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Sigmoid Function\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmoidFunction_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Sigmoid Function Derivative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Draw the grid line in background.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b9bc1d3e6a1e>\u001b[0m in \u001b[0;36msigmoidFunction_derivative\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoidFunction_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sigmoid' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoidFunction(x):\n",
    "    s = 1/(1+np.exp(-x))   \n",
    "    return s\n",
    "\n",
    "def sigmoidFunction_derivative(x):\n",
    "    s = sigmoidFunction(x)\n",
    "    ds = s*(1-s)\n",
    "    return ds\n",
    "\n",
    "# linespace generate an array from start and stop value, 100 elements\n",
    "values = np.linspace(-10,10,100)\n",
    "\n",
    "# prepare the plot, associate the color r(ed) or b(lue) and the label \n",
    "plt.plot(values, sigmoidFunction(values), 'r', label=\"Sigmoid Function\")\n",
    "plt.plot(values, sigmoidFunction_derivative(values), 'b',label=\"Sigmoid Function Derivative\")\n",
    "\n",
    "# Draw the grid line in background.\n",
    "plt.grid()\n",
    "\n",
    "# plt.plot(x)\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "\n",
    "# create the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "***Learning Curves***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def run_net(Layer1, Layer2, epochs):\n",
    "epochs=25\n",
    "#Network (3 weigthed layers)\n",
    "net = neuralNetwork()\n",
    "net.add_layer(Dense(28*28, 300))  # input_layer : 784 nodes\n",
    "net.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative)) # Hidden Layer 1 : 300 nodes\n",
    "net.add_layer(Dense(300, 100)) # Hidden Layer 2 : 100 nodes\n",
    "net.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "net.add_layer(Dense(100, 10))\n",
    "net.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "net.use_lossfunc(mse_loss, mse_loss_derivative)\n",
    "#network.accuracy(X_train[0:1000], y_train[0:1000],X_test[0:1000],y_test[0:1000])\n",
    "#predict_digit = run_net(300, 100, 25)\n",
    "\n",
    "net_mom=neuralNetwork_mom()\n",
    "net_mom.add_layer(Dense(28*28, 300))  # input_layer : 784 nodes\n",
    "net_mom.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative)) # Hidden Layer 1 : 300 nodes\n",
    "net_mom.add_layer(Dense(300, 100)) # Hidden Layer 2 : 100 nodes\n",
    "net_mom.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "net_mom.add_layer(Dense(100, 10))\n",
    "net_mom.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "net_mom.use_lossfunc(mse_loss, mse_loss_derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Error on training ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorList = []\n",
    "errorList_mom=[]\n",
    "errorList.append(net.train_network(X_train[0:1000], y_train[0:1000], epochs, learningRate=0.1))\n",
    "errorList_mom.append(net_mom.train_network_mom(X_train[0:1000], y_train[0:1000], epochs, learningRate=0.1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(errorList[0], '-r', label='Sigmoid')\n",
    "ax.plot(errorList_mom[0], '-g', label='Sigmoid w/ momentum')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Mean Squarred Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Error on testing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errorList = []\n",
    "test_errorList_mom=[]\n",
    "test_errorList.append(net.train_network(X_test[0:1000], y_test[0:1000], epochs, learningRate=0.1))\n",
    "test_errorList_mom.append(net_mom.train_network_mom(X_test[0:1000], y_test[0:1000], epochs, learningRate=0.1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(test_errorList[0], '-r', label='Sigmoid')\n",
    "ax.plot(test_errorList_mom[0], '-g', label='Sigmoid w/ momentum')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Mean Squarred Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Activation Function : ReLU\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def dReLU(x):\n",
    "    return 1. * (x > 0)\n",
    "\n",
    "# linespace generate an array from start and stop value, 100 elements\n",
    "values = np.linspace(-10,10,100)\n",
    "\n",
    "# prepare the plot, associate the color r(ed) or b(lue) and the label \n",
    "plt.plot(values, ReLU(values), 'r', label=\" ReLU Function\")\n",
    "plt.plot(values, dReLU(values), 'b',label=\"ReLU Function Derivative\")\n",
    "# Draw the grid line in background.\n",
    "plt.grid()\n",
    "# plt.plot(x)\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "# create the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network (3 weigthed layers)\n",
    "net_relu= neuralNetwork()\n",
    "net_relu.add_layer(Dense(28*28, 300))\n",
    "net_relu.add_layer(ActivateLayer(ReLU, dReLU))\n",
    "net_relu.add_layer(Dense(300, 100))\n",
    "net_relu.add_layer(ActivateLayer(ReLU, dReLU))\n",
    "net_relu.add_layer(Dense(100, 10))\n",
    "net_relu.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "net_relu.use_lossfunc(mse_loss, mse_loss_derivative)\n",
    "#network.accuracy(X_train[0:1000], y_train[0:1000],X_test[0:1000],y_test[0:1000])\n",
    "net_relu_mom= neuralNetwork_mom()\n",
    "net_relu_mom.add_layer(Dense(28*28, 300))\n",
    "net_relu_mom.add_layer(ActivateLayer(ReLU, dReLU))\n",
    "net_relu_mom.add_layer(Dense(300, 100))\n",
    "net_relu_mom.add_layer(ActivateLayer(ReLU, dReLU))\n",
    "net_relu_mom.add_layer(Dense(100, 10))\n",
    "net_relu_mom.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "net_relu_mom.use_lossfunc(mse_loss, mse_loss_derivative)\n",
    "\n",
    "\n",
    "    \n",
    "# input_layer : 784 nodes\n",
    "# Hidden Layer 1 : 300 nodes\n",
    "# Hidden Layer 2 : 100 nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Error on training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errorList_relu=[]\n",
    "train_errorList_relu_mom=[]\n",
    "train_errorList_relu.append(net_relu.train_network(X_train[0:100], y_train[0:100], epochs, learningRate=0.1))\n",
    "train_errorList_relu_mom.append(net_relu_mom.train_network_mom(X_train[0:100], y_train[0:100], epochs, learningRate=0.1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_errorList_relu[0], '-r', label='ReLU')\n",
    "ax.plot(train_errorList_relu_mom[0], '-g', label='ReLU w/ momentum')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Mean Squarred Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error on testing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errorList_relu=[]\n",
    "test_errorList_relu_mom=[]\n",
    "test_errorList_relu.append(net_relu.train_network(X_train[0:100], y_train[0:100], epochs, learningRate=0.1))\n",
    "test_errorList_relu_mom.append(net_relu_mom.train_network_mom(X_train[0:100], y_train[0:100], epochs, learningRate=0.1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(test_errorList_relu[0], '-r', label='ReLU')\n",
    "ax.plot(test_errorList_relu_mom[0], '-g', label='ReLU w/ momentum')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Mean Squarred Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "C. Stochastic Gradient Descent\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_net_sgd(Layer1, Layer2, epochs):\n",
    "    errorList=[]\n",
    "    errorList_mom=[]\n",
    "    # Network (3 weigthed layers)\n",
    "    network = neuralNetwork()\n",
    "    network.add_layer(Dense(28*28, Layer1))\n",
    "    network.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "    network.add_layer(Dense(Layer1, Layer2))\n",
    "    network.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "    network.add_layer(Dense(Layer2, 10))\n",
    "    network.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "\n",
    "    # train on 1000 samples\n",
    "    # training will be slow if we update at each iteration on 60000 samples\n",
    "    # compromise with 250 epochs for the precision & time with L1 of 100 and L2 of 50 neurons\n",
    "    network.use_lossfunc(mse_loss, mse_loss_derivative)\n",
    "    for epoch in range(1):\n",
    "        for i in range(2500):\n",
    "            random_idx=np.random.randint(0,60000)\n",
    "            errorList.append(network.train_network(X_train[random_idx:random_idx+1], y_train[random_idx:random_idx+1],1, learningRate=0.1))\n",
    "            errorList_mom.append(network.train_network_mom(X_train[random_idx:random_idx+1], y_train[random_idx:random_idx+1],1, learningRate=0.1))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(errorList, '-r', label='SGD ')\n",
    "    ax.plot(errorList_mom, '-g', label='SGD w/momentum')\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Mean Squarred Error')\n",
    "    plt.show()\n",
    "# input_layer : 784 nodes\n",
    "# Hidden Layer 1 : 300 nodes\n",
    "# Hidden Layer 2 : 100 nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Error on training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_digit = run_net_sgd(300, 100, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Mini Batch Gradient Descent\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_net_mbgd(Layer1, Layer2, epochs):\n",
    "    errorList=[]\n",
    "    errorList_mom=[]\n",
    "    # Network (3 weigthed layers)\n",
    "    network = neuralNetwork()\n",
    "    network.add_layer(Dense(28*28, Layer1))\n",
    "    network.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "    network.add_layer(Dense(Layer1, Layer2))\n",
    "    network.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "    network.add_layer(Dense(Layer2, 10))\n",
    "    network.add_layer(ActivateLayer(sigmoidFunction, sigmoidFunction_derivative))\n",
    "\n",
    "    # train on 1000 samples\n",
    "    # training will be slow if we update at each iteration on 60000 samples\n",
    "    # compromise with 250 epochs for the precision & time with L1 of 100 and L2 of 50 neurons\n",
    "    network.use_lossfunc(mse_loss, mse_loss_derivative)\n",
    "    X_train_mbgd = X_train\n",
    "    y_train_mbgd = y_train\n",
    "    epochs=1\n",
    "    mini_batch_size=300\n",
    "    no_batches=2\n",
    "    samples=int(mini_batch_size/no_batches)\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(1000):\n",
    "            shuffle = np.random.permutation(60000)\n",
    "            shuffle=shuffle[:samples]\n",
    "            X_train_mbgd = X_train[shuffle]\n",
    "            y_train_mbgd=y_train[shuffle]\n",
    "            errorList.append(network.train_network(X_train_mbgd, y_train_mbgd,1, learningRate=0.1))\n",
    "            errorList_mom.append(network.train_network_mom(X_train_mbgd, y_train_mbgd,1, learningRate=0.1))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(errorList, '-r', label='MBGD ')\n",
    "    ax.plot(errorList_mom, '-g', label='MBGD w/momentum')\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Mean Squarred Error')\n",
    "    plt.show()\n",
    "# input_layer : 784 nodes\n",
    "# Hidden Layer 1 : 300 nodes\n",
    "# Hidden Layer 2 : 100 nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error on training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_digit = run_net_mbgd(300, 100, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_conf_matrix_values(y_true,y_pred):\n",
    "    # calculate TP, FN, FP, TN\n",
    "    TP = find_TP(y_true,y_pred)\n",
    "    FN = find_FN(y_true,y_pred)\n",
    "    FP = find_FP(y_true,y_pred)\n",
    "    TN = find_TN(y_true,y_pred)\n",
    "    return TP,FN,FP,TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy_score(y_true, y_pred):\n",
    "    # calculates the fraction of samples predicted correctly\n",
    "    TP,FN,FP,TN = find_conf_matrix_values(y_true,y_pred)\n",
    "    accuracy=(TP+TN)/(TP+TN+FP+TN)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc=[]\n",
    "#acc.append(my_accuracy_score(y_test[0:1000], predict_digit[0:1000]))\n",
    "#plt.plot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
